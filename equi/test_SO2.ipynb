{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hnguyen/nghia_branch/ourproject/equiRL\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hnguyen/miniconda3/envs/softgym/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as model_pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = np.load(\"data/RNN_imitation/video/demo_npy/data_1.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[216, 216, 216,  ..., 246, 246, 246],\n",
       "          [216, 216, 216,  ..., 246, 246, 246],\n",
       "          [216, 216, 216,  ..., 246, 246, 246],\n",
       "          ...,\n",
       "          [246, 246, 246,  ..., 216, 216, 216],\n",
       "          [246, 246, 246,  ..., 216, 216, 216],\n",
       "          [246, 246, 246,  ..., 216, 216, 216]],\n",
       "\n",
       "         [[213, 213, 213,  ..., 243, 243, 243],\n",
       "          [213, 213, 213,  ..., 243, 243, 243],\n",
       "          [213, 213, 213,  ..., 243, 243, 243],\n",
       "          ...,\n",
       "          [243, 243, 243,  ..., 213, 213, 213],\n",
       "          [243, 243, 243,  ..., 213, 213, 213],\n",
       "          [243, 243, 243,  ..., 213, 213, 213]],\n",
       "\n",
       "         [[213, 213, 213,  ..., 243, 243, 243],\n",
       "          [213, 213, 213,  ..., 243, 243, 243],\n",
       "          [213, 213, 213,  ..., 243, 243, 243],\n",
       "          ...,\n",
       "          [243, 243, 243,  ..., 213, 213, 213],\n",
       "          [243, 243, 243,  ..., 213, 213, 213],\n",
       "          [243, 243, 243,  ..., 213, 213, 213]]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TanhWrappedDistribution(torch.distributions.Distribution):\n",
    "    \"\"\"\n",
    "    Class that wraps another valid torch distribution, such that sampled values from the base distribution are\n",
    "    passed through a tanh layer. The corresponding (log) probabilities are also modified accordingly.\n",
    "    Tanh Normal distribution - adapted from rlkit and CQL codebase\n",
    "    (https://github.com/aviralkumar2907/CQL/blob/d67dbe9cf5d2b96e3b462b6146f249b3d6569796/d4rl/rlkit/torch/distributions.py#L6).\n",
    "    \"\"\"\n",
    "    def __init__(self, base_dist, scale=1.0, epsilon=1e-6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            base_dist (Distribution): Distribution to wrap with tanh output\n",
    "            scale (float): Scale of output\n",
    "            epsilon (float): Numerical stability epsilon when computing log-prob.\n",
    "        \"\"\"\n",
    "        self.base_dist = base_dist\n",
    "        self.scale = scale\n",
    "        self.tanh_epsilon = epsilon\n",
    "        super(TanhWrappedDistribution, self).__init__()\n",
    "\n",
    "    def log_prob(self, value, pre_tanh_value=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            value (torch.Tensor): some tensor to compute log probabilities for\n",
    "            pre_tanh_value: If specified, will not calculate atanh manually from @value. More numerically stable\n",
    "        \"\"\"\n",
    "        value = value / self.scale\n",
    "        if pre_tanh_value is None:\n",
    "            one_plus_x = (1. + value).clamp(min=self.tanh_epsilon)\n",
    "            one_minus_x = (1. - value).clamp(min=self.tanh_epsilon)\n",
    "            pre_tanh_value = 0.5 * torch.log(one_plus_x / one_minus_x)\n",
    "        lp = self.base_dist.log_prob(pre_tanh_value)\n",
    "        tanh_lp = torch.log(1 - value * value + self.tanh_epsilon)\n",
    "        # In case the base dist already sums up the log probs, make sure we do the same\n",
    "        return lp - tanh_lp if len(lp.shape) == len(tanh_lp.shape) else lp - tanh_lp.sum(-1)\n",
    "    def sample(self, sample_shape=torch.Size(), return_pretanh_value=False):\n",
    "        \"\"\"\n",
    "        Gradients will and should *not* pass through this operation.\n",
    "        See https://github.com/pytorch/pytorch/issues/4620 for discussion.\n",
    "        \"\"\"\n",
    "        z = self.base_dist.sample(sample_shape=sample_shape).detach()\n",
    "\n",
    "        if return_pretanh_value:\n",
    "            return torch.tanh(z) * self.scale, z\n",
    "        else:\n",
    "            return torch.tanh(z) * self.scale\n",
    "\n",
    "    def rsample(self, sample_shape=torch.Size(), return_pretanh_value=False):\n",
    "        \"\"\"\n",
    "        Sampling in the reparameterization case - for differentiable samples.\n",
    "        \"\"\"\n",
    "        z = self.base_dist.rsample(sample_shape=sample_shape)\n",
    "\n",
    "        if return_pretanh_value:\n",
    "            return torch.tanh(z) * self.scale, z\n",
    "        else:\n",
    "            return torch.tanh(z) * self.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BC_RNN_GMM_actor(nn.Module):\n",
    "    def __init__(self, obs_shape = (3,224,224), device = \"cpu\", node = 5):\n",
    "        super(BC_RNN_GMM_actor, self).__init__()\n",
    "        self.channel = obs_shape[0]\n",
    "        self.device = device\n",
    "        self.node = node\n",
    "        self.encoder = model_pretrain.resnet50(pretrained = True)\n",
    "\n",
    "        self.encoder.load_state_dict(torch.load(\"data/RNN_imitation/model/byol.pt\"))\n",
    "\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.per_step_mean = nn.Linear(200, node*8)\n",
    "        self.per_step_std = nn.Linear(200, node*8)\n",
    "        self.per_step_logit = nn.Linear(200, node)\n",
    "\n",
    "        self.rnn = nn.LSTM(1100, 200 , 2, batch_first=True)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x, picker_state, init_state = None, train = True):\n",
    "        # Process the input image with the CNN\n",
    "        length = x.shape[1]\n",
    "        x = x.view(x.size(0)*x.size(1),x.size(2),x.size(3),x.size(4))\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        x = x.view(-1,length,x.size(1))\n",
    "\n",
    "        x = torch.cat((x, picker_state), dim = 2)\n",
    "        \n",
    "        if init_state is None:\n",
    "            h0 = torch.zeros(2,x.size(0),200).to(self.device)\n",
    "            c0 = torch.zeros(2,x.size(0),200).to(self.device)\n",
    "            init_state = (h0,c0)\n",
    "        out, (hn,cn) = self.rnn(x, init_state)\n",
    "\n",
    "        out = out.contiguous().view(-1,200)\n",
    "\n",
    "        mean = self.per_step_mean(out)\n",
    "\n",
    "        mean = mean.view(-1, length, self.node, 8)\n",
    "\n",
    "        std = self.per_step_std(out)\n",
    "        \n",
    "        std = std.view(-1, length, self.node, 8)\n",
    "\n",
    "        logits = self.per_step_logit(out)\n",
    "\n",
    "        logits = logits.view(-1, length, self.node)\n",
    "\n",
    "\n",
    "        if not train:\n",
    "            std = torch.ones_like(mean) * 1e-4\n",
    "        else:\n",
    "            std = torch.nn.functional.softplus(std) + 1e-4\n",
    "\n",
    "        component_distribution = torch.distributions.Normal(loc=mean, scale=std)\n",
    "        component_distribution = torch.distributions.Independent(component_distribution, 1)\n",
    "        mixture_distribution = torch.distributions.Categorical(logits=logits)\n",
    "\n",
    "        dists = torch.distributions.MixtureSameFamily(\n",
    "            mixture_distribution=mixture_distribution,\n",
    "            component_distribution=component_distribution,\n",
    "        )\n",
    "\n",
    "        dists = TanhWrappedDistribution(base_dist=dists, scale=1.)\n",
    "\n",
    "        return dists, hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BC_RNN_GMM_actor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = torch.randn(1, 30, 3, 224, 224)\n",
    "picker_state = torch.randn(1, 30, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists, hn, cn = model(obs, picker_state, train = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "softgym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a70e410a95a92e7efbb302c62263abaa2138db43536f2d92d4b110b7da6b08d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
